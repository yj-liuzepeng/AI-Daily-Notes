# AI-Daily-Notes

1. 大模型推理/生成阶段的两个参数 temperature 和 top-p：大模型在推理生成时，其实就是根据概率预测下一个词，模型输出的是一组原始分数（Logits），在转化为概率（Softmax）之前，会把这些分数除以 temperature (T)，从而**控制输出概率**，temperature越小，输出相对越稳定，temperature越大，输出相对就会发散 ，就如这个词意温度一样，水低温时稳定成固态，高温时不稳定会挥发。top-p控制的也是输出的概率，越小，输出越保守，越稳定，越大输出的答案越发散。推荐只用一种即可，一句话描述： temperature 熵增熵减，top-p 去尾。（8.97 复制打开抖音，看看【马克的技术工作坊的作品】Temperature & Top-p：大模型的创... https://v.douyin.com/GgkLeHOHKXI/ r@E.uF 12/05 OKw:/ ）
2. Context Engineering：一个token大概0.75个单词，或者1.5个汉字，大语言模型面对的三个问题 1.Context Window非常有限2.输入太杂乱会影响模型输出3.输出阅读，成本越高  ----> 解决就是Context Engineering，目的是精心设计给模型输入的内容，让模型在有限的Context Window中回答的更好，核心思想是不改变模型结构，而是改变模型看到什么。
   四部分：1.保存Context，把输入进行筛选总结，进行保存，一般是内存/硬盘；2.选择Context，在存下来的记忆库中精准找到需要的信息，分为静态选择和动态选择，静态选择就是把一些永远重要的信息始终放在Context中，比如cursor这种编辑器中的rules文件，动态选择，就是选择与用户最相关的内容放到Context中，有很多实现方式比如RAG；3.压缩Context，Context中最占空间的两类数据一般是模型的输出文本和工具的执行结果，对历史消息进行压缩，例如claude编辑器，当历史内容过多时，会调用auto-compact对之前内容进行总结，记录重要内容，进行体积压缩；4.隔离Context，不同模块之间的Context相互隔离，互不干扰，如一些subagent互相隔离。
3. Tokenizer即分词器（文本与模型之间的桥梁），将文本转换为模型能理解的数字（Token ID），负责建立 文本<-->数字 映射关系的字典和规则集。特点：1. 压缩信息，节省token，控制输入长度，提升效率；2.能处理未见过的词汇，好的Tokenizer能把未见过的词汇拆解成已知部分；3.可以统一多语言，使用一个统一的策略；Tokenizer 词汇表通常控制在 2 万到 10 万+之间，太小：成本增加，太大：模型嵌入层参数爆炸，每个 token 的语义表示可能不够稠密。特殊标记：开始结束<BOS>/<EOS>， 填充<PAD>，分隔符：<SEP>，未知标记：<UNK>
4. 分享一个AI记忆系统的搭建思路：“我希望建立一套我与 AI 交互的记忆系统，帮助我抽象和提炼出自己价值观、性格特征、心智模式、思维模式、工作习惯、行为偏好、决策原则、关注方向等，将来可以让 AI 更好地与我合作，甚至模拟我的决策，你帮我想想这套记忆系统该怎么搭建，它应该是一个可以根据我与 AI 的日常互动，不能够学习和迭代的，实现持续动态更新的记忆系统。” 五层：l0，状态层，每一次和AI的对话都将它沉淀下来（值得记录的事情），l1，情景层，近期我在关注什么，重点的上下文信息是什么，l2，行为层，我的行为模式，提炼出来，l3，认知层，一段时间的对行为模式，认知偏好的提炼和观察，抽象出来，l4，核心层，比较底层的信息，我的价值观是怎样的，性格，能量等等。 此外，又提炼了一个小的文件夹，记录一些我个人的要求，目标，以及AI决策的一些边界红线等等。
